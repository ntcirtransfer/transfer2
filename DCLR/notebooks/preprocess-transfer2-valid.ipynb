{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1931b00-c8c4-4d9c-822c-205bb86d9a65",
   "metadata": {},
   "source": [
    "# Preprocessing of NTCIR-18 Transfer 2 DCLR Subtask (Valid Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deec37a-3388-4195-8d35-2d4c0a4d21de",
   "metadata": {
    "tags": []
   },
   "source": [
    "## About the subtask\n",
    "\n",
    "NTCIR-18 Transfer DCLR Subask aims to retrieve English documents from Japanese topics.\n",
    "\n",
    "\n",
    "## About the dataset\n",
    "\n",
    "NTCIR-18 Transfer DCLR Subask uses the following test collections as the validation set.\n",
    "\n",
    "### Overview of NTCIR-2 Cross-Lingual IR Test Collection\n",
    "- Reference\n",
    "> Kando, et al. (2001). [Overview of Japanese and English Information Retrieval Tasks (JEIR) at the Second NTCIR Workshop](http://research.nii.ac.jp/ntcir/workshop/OnlineProceedings2/ovview-kando2.pdf). In: Proceedings of the Second NTCIR Workshop on Research in Chinese & Japanese Text Retrieval and Text Summarization, May 2000- March 2001.\n",
    "- How to obtain the data: [Research Purpose Use of NTCIR Test Collections or Data Archive/ User Agreement](http://research.nii.ac.jp/ntcir/permission/perm-en.html#ntcir-2)\n",
    "> The collection includes (1) Document data (Author abstracts of the Academic Conference Paper Database (1997-1999) and Grant Reports (1988-1997) = about 400,000 Japanese and 130,000 English documents,) (2) 49 Search topics (Japanese and English,) and (3) Relevance Judgements. The whole test collection is available for research purpose use from NII For experiments, the document data must be used with those of the NTCIR-1. Relevance judgments were done of the merged database of NTCIR-1 and NTCIR-2. To merge document collections, the document IDs in the NTCIR-1 must be converted using the script included in the NTCIR-2 CD-ROM. At the Second NTCIR Workshop, segmented data, in which the whole document data were segmented into terms (short units as well as longer units) using the standard software for segmentation in the year of 2000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e34d4",
   "metadata": {},
   "source": [
    "## Previous Step\n",
    "\n",
    "- `preprocess-transfer2-train.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf26c1c8-1e00-44d7-8e82-de1815b8600c",
   "metadata": {},
   "source": [
    "## Data path\n",
    "- Get a copy of the test collections based on the above instruction.\n",
    "- We assume that the downloaded file has been uncompressed to the following path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3fde54b-cab1-4a39-ab54-e0706954dfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "NTCIR1 = os.getcwd() + '/../testcollections/ntcir/NTCIR-1'\n",
    "NTCIR2 = os.getcwd() + '/../testcollections/ntcir/NTCIR-2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebfbfc3d-b414-4cc6-9e97-f1819ec33ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADHOC.TGZ',\n",
       " 'AGREEM-E.PDF',\n",
       " 'AGREEM-J.PDF',\n",
       " 'clir',\n",
       " 'CLIR.TGZ',\n",
       " 'CORRECTION-E-130709.pdf',\n",
       " 'CORRECTION-J-130705.pdf',\n",
       " 'MANUAL-E.PDF',\n",
       " 'MANUAL-J.PDF',\n",
       " 'mlir',\n",
       " 'MLIR.TGZ',\n",
       " 'README-E-REVISED-130709.pdf',\n",
       " 'README-E.TXT',\n",
       " 'README-J-REVISED-130705.pdf',\n",
       " 'README-J.PDF',\n",
       " 'README-J.TXT',\n",
       " 'TAGREE-E.PDF',\n",
       " 'TAGREE-J.PDF',\n",
       " 'TMREC.TGZ',\n",
       " 'topics',\n",
       " 'TOPICS.TGZ']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(NTCIR1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8a88820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agreem2-e.pdf',\n",
       " 'agreem2-j.pdf',\n",
       " 'correction-e-130709.pdf',\n",
       " 'correction-j-130705.pdf',\n",
       " 'e-docs',\n",
       " 'e-docs.tgz',\n",
       " 'j-docs',\n",
       " 'j-docs.tgz',\n",
       " 'manual-e.pdf',\n",
       " 'manual-j.pdf',\n",
       " 'readme-e-revised-130709.pdf',\n",
       " 'readme-e.txt',\n",
       " 'readme-j-revised-130709.pdf',\n",
       " 'readme-j.pdf',\n",
       " 'readme-j.txt',\n",
       " 'rels',\n",
       " 'rels.tgz',\n",
       " 'scripts.tgz',\n",
       " 'topics',\n",
       " 'topics.tgz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea1ab8f-a0be-49dc-904a-5f1a060b5403",
   "metadata": {},
   "source": [
    "## Preprocessing of NTCIR-2 Dataset\n",
    "\n",
    "### Corpus files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f21b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "tarfile.open(NTCIR2 + '/e-docs.tgz').extractall(path=NTCIR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80a929cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ntc2-e1g', 'ntc2-e1k']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/e-docs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62ea02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "def convert_encoding(input_file_path, output_file_path, input_encoding, output_encoding, error_handling='ignore'):\n",
    "    # Open the input file with the specified encoding\n",
    "    with codecs.open(input_file_path, 'r', encoding=input_encoding, errors=error_handling) as file:\n",
    "        contents = file.read()\n",
    "    \n",
    "    # Open the output file with the desired encoding\n",
    "    with codecs.open(output_file_path, 'w', encoding=output_encoding) as file:\n",
    "        file.write(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0abe511",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_encoding(NTCIR2 + '/e-docs/ntc2-e1g', NTCIR2 + '/e-docs/ntc2-e1g.utf8', 'ascii', 'utf-8')\n",
    "convert_encoding(NTCIR2 + '/e-docs/ntc2-e1k', NTCIR2 + '/e-docs/ntc2-e1k.utf8', 'ascii', 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8b8a619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ntc2-e1g', 'ntc2-e1g.utf8', 'ntc2-e1k', 'ntc2-e1k.utf8']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/e-docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26973e89",
   "metadata": {},
   "source": [
    "#### ntc2-e1g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aa8f958-57c2-49bc-ad1d-b47a0f3eccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import json\n",
    "def docs_g_jsonl(in_file):\n",
    "    out_file = in_file + '.jsonl'\n",
    "    with open(in_file, 'r', encoding='utf-8') as f, open(out_file, 'w', encoding='utf-8') as f1:\n",
    "        record = ''\n",
    "        items = {}\n",
    "        count = 0\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            if line == '</REC>':\n",
    "                accn = re.findall(r'<ACCN>(.+?)<', record)[0]\n",
    "                titl = re.findall(r'<TITE .+?>(.+?)<', record)[0]\n",
    "                abst = re.findall(r'<ABSE .+?>(.+?)</ABSE>', record)[0]\n",
    "                abst = re.sub(r'<ABSE.P>', '', abst)\n",
    "                abst = re.sub(r'</ABSE.P>', '', abst)\n",
    "                contents = titl + ' ' + abst\n",
    "                items = {\n",
    "                    'doc_id': accn,\n",
    "                    'text': contents\n",
    "                }\n",
    "                j = json.dumps(items, ensure_ascii=False)\n",
    "                f1.write(f'{j}\\n')\n",
    "                record = ''\n",
    "                items = {}\n",
    "                count += 1\n",
    "                if count % 10000 == 0:\n",
    "                    print(f'{count}, ', end='', file=sys.stderr)\n",
    "            else:\n",
    "                record += line\n",
    "        print(f'{count}, Done!', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35d4bae1-9ddf-44a7-9fe8-c6f9ccb8f8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000, 20000, 30000, 40000, 50000, 60000, 70000, 77433, Done!\n"
     ]
    }
   ],
   "source": [
    "docs_g_jsonl(NTCIR2 + '/e-docs/ntc2-e1g.utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762cda3a",
   "metadata": {},
   "source": [
    "#### ntc2-e1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9aa4276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs_k_jsonl(in_file):\n",
    "    out_file = in_file + '.jsonl'\n",
    "    with open(in_file, 'r', encoding='utf-8') as f, open(out_file, 'w', encoding='utf-8') as f1:\n",
    "        record = ''\n",
    "        items = {}\n",
    "        count = 0\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            if line == '</REC>':\n",
    "                accn = re.findall(r'<ACCN>(.+?)<', record)[0]\n",
    "                titl = re.findall(r'<PJNE .+?>(.+?)<', record)[0] # Difference\n",
    "                abst = re.findall(r'<ABSE .+?>(.+?)</ABSE>', record)[0]\n",
    "                abst = re.sub(r'<ABSE.P>', '', abst)\n",
    "                abst = re.sub(r'</ABSE.P>', '', abst)\n",
    "                contents = titl + ' ' + abst\n",
    "                items = {\n",
    "                    'doc_id': accn,\n",
    "                    'text': contents\n",
    "                }\n",
    "                j = json.dumps(items, ensure_ascii=False)\n",
    "                f1.write(f'{j}\\n')\n",
    "                record = ''\n",
    "                items = {}\n",
    "                count += 1\n",
    "                if count % 10000 == 0:\n",
    "                    print(f'{count}, ', end='', file=sys.stderr)\n",
    "            else:\n",
    "                record += line\n",
    "        print(f'{count}, Done!', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9521bc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000, 20000, 30000, 40000, 50000, 57545, Done!\n"
     ]
    }
   ],
   "source": [
    "docs_k_jsonl(NTCIR2 + '/e-docs/ntc2-e1k.utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7dcc7f-4625-41d3-8f1e-74b4c0a24424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ntc2-e1g',\n",
       " 'ntc2-e1g.utf8',\n",
       " 'ntc2-e1g.utf8.jsonl',\n",
       " 'ntc2-e1k',\n",
       " 'ntc2-e1k.utf8',\n",
       " 'ntc2-e1k.utf8.jsonl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/e-docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd976fbd",
   "metadata": {},
   "source": [
    "#### NTCIR-1 Corpus file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d522425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "def convert_ntcir1_to_ntcir2(in_file, out_file):\n",
    "    with open(in_file, 'r', encoding='utf-8') as f, open(out_file, 'w', encoding='utf-8') as f2:\n",
    "        for i, line in enumerate(f):\n",
    "            j = json.loads(line)\n",
    "            docid = j['doc_id'].replace('gakkai-', 'gakkai-e-')\n",
    "            j['doc_id'] = docid\n",
    "            jline = json.dumps(j, ensure_ascii=False)\n",
    "            f2.write(f'{jline}\\n')\n",
    "            if i % 10000 == 0:\n",
    "                print(f'{i}, ', end='', file=sys.stderr)\n",
    "        print(f'{i}, Done!', file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95048b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0, 10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000, 110000, 120000, 130000, 140000, 150000, 160000, 170000, 180000, 187079, Done!\n"
     ]
    }
   ],
   "source": [
    "convert_ntcir1_to_ntcir2(\n",
    "    NTCIR1 + '/clir/ntc1-e1.utf8.jsonl',\n",
    "    NTCIR2 + '/e-docs/ntc1-e1.utf8.mod.jsonl'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8878ecd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_files(file_path1, file_path2, output_file_path):\n",
    "    with open(file_path1, 'r', encoding='utf-8') as file1:\n",
    "        data1 = file1.read()\n",
    "        \n",
    "    with open(file_path2, 'r', encoding='utf-8') as file2:\n",
    "        data2 = file2.read()\n",
    "    \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n",
    "        outfile.write(data1)\n",
    "        outfile.write(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee9f4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_files(NTCIR2 + '/e-docs/ntc2-e1g.utf8.jsonl', NTCIR2 + '/e-docs/ntc2-e1k.utf8.jsonl', NTCIR2 + '/e-docs/ntc2-e1.utf8.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94bf392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenate_files(NTCIR2 + '/e-docs/ntc1-e1.utf8.mod.jsonl', NTCIR2 + '/e-docs/ntc2-e1.utf8.jsonl', NTCIR2 + '/e-docs/ntc12-e1gk.utf8.mod.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ab8288f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ntc1-e1.utf8.mod.jsonl',\n",
       " 'ntc12-e1gk.utf8.mod.jsonl',\n",
       " 'ntc2-e1.utf8.jsonl',\n",
       " 'ntc2-e1g',\n",
       " 'ntc2-e1g.utf8',\n",
       " 'ntc2-e1g.utf8.jsonl',\n",
       " 'ntc2-e1k',\n",
       " 'ntc2-e1k.utf8',\n",
       " 'ntc2-e1k.utf8.jsonl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/e-docs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81262343-ca48-4196-997f-24e08f47fd5a",
   "metadata": {},
   "source": [
    "### Topic files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f8b3153-83db-4119-8533-301f9b19cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarfile.open(NTCIR2 + '/topics.tgz').extractall(path=NTCIR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b666c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic-e0101-0149', 'topic-j0101-0149']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24be292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_encoding(NTCIR2 + '/topics/topic-j0101-0149', NTCIR2 + '/topics/topic-j0101-0149.utf8', 'euc_jp', 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89e5159f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic-e0101-0149', 'topic-j0101-0149', 'topic-j0101-0149.utf8']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/topics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f600d291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def topics_jsonl(in_file):\n",
    "    out_file = in_file + '.jsonl'\n",
    "    with open(in_file, 'r', encoding='utf-8') as f:\n",
    "        s = f.read()\n",
    "        qid = re.findall('<TOPIC q=([^>]+)>', s)\n",
    "        title = re.findall('<TITLE>\\n(.*)\\n</TITLE>', s)\n",
    "        desc = re.findall('<DESCRIPTION>\\n(.*)\\n</DESCRIPTION>', s)\n",
    "    with open(out_file, 'w', encoding='utf-8') as f:\n",
    "        for i in range(len(qid)):\n",
    "            f.write(f'{{ \"query_id\": \"{qid[i]}\", \"text\": \"{title[i]}\", \"description\": \"{desc[i]}\" }}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4658df8-96d0-4b58-b89a-9c8285bc44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_jsonl(NTCIR2 + '/topics/topic-j0101-0149.utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684bec1e-911e-4efb-a27d-0a3b3e9dd55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic-e0101-0149',\n",
       " 'topic-j0101-0149',\n",
       " 'topic-j0101-0149.utf8',\n",
       " 'topic-j0101-0149.utf8.jsonl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c78ef8-bea6-4d20-a300-a1c3df9a99f2",
   "metadata": {},
   "source": [
    "### Qrel files\n",
    "- This test collection provides graded relevance scores (A: Relevant, B: Partially Relevant, C: Not Relevant)\n",
    "- We convert them as follows.\n",
    "    - A: 2\n",
    "    - B: 1\n",
    "    - C: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a82f71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tarfile.open(NTCIR2 + '/rels.tgz').extractall(path=NTCIR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2334f65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rel1_ntc2-e2_0101-0149',\n",
       " 'rel1_ntc2-e2_0101-0149.nc',\n",
       " 'rel1_ntc2-j2_0101-0149',\n",
       " 'rel1_ntc2-j2_0101-0149.nc',\n",
       " 'rel1_ntc2-je2_0101-0149',\n",
       " 'rel1_ntc2-je2_0101-0149.nc',\n",
       " 'rel2_ntc2-e2_0101-0149',\n",
       " 'rel2_ntc2-e2_0101-0149.nc',\n",
       " 'rel2_ntc2-j2_0101-0149',\n",
       " 'rel2_ntc2-j2_0101-0149.nc',\n",
       " 'rel2_ntc2-je2_0101-0149',\n",
       " 'rel2_ntc2-je2_0101-0149.nc']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/rels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55368bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_encoding(NTCIR2 + '/rels/rel2_ntc2-je2_0101-0149.nc', NTCIR2 + '/rels/rel2_ntc2-je2_0101-0149.nc.utf8', 'ascii', 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "00f580a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rel1_ntc2-e2_0101-0149',\n",
       " 'rel1_ntc2-e2_0101-0149.nc',\n",
       " 'rel1_ntc2-j2_0101-0149',\n",
       " 'rel1_ntc2-j2_0101-0149.nc',\n",
       " 'rel1_ntc2-je2_0101-0149',\n",
       " 'rel1_ntc2-je2_0101-0149.nc',\n",
       " 'rel2_ntc2-e2_0101-0149',\n",
       " 'rel2_ntc2-e2_0101-0149.nc',\n",
       " 'rel2_ntc2-j2_0101-0149',\n",
       " 'rel2_ntc2-j2_0101-0149.nc',\n",
       " 'rel2_ntc2-je2_0101-0149',\n",
       " 'rel2_ntc2-je2_0101-0149.nc',\n",
       " 'rel2_ntc2-je2_0101-0149.nc.utf8']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/rels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbba2e8d-f935-4b29-aa46-aa1dddc38aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qrel_graded_tsv(in_file):\n",
    "    out_file = in_file + '.tsv'\n",
    "    with open(in_file, 'r', encoding='utf-8') as f, open(out_file, 'w', encoding='utf-8') as f2:\n",
    "        for line in f:\n",
    "            line = line.rstrip()\n",
    "            flds = line.split('\\t')\n",
    "            if flds[1] == 'A':\n",
    "                f2.write(f'{flds[0]}\\tQ0\\t{flds[2]}\\t2\\n')\n",
    "            if flds[1] == 'B':\n",
    "                f2.write(f'{flds[0]}\\tQ0\\t{flds[2]}\\t1\\n')\n",
    "            if flds[1] == 'C':\n",
    "                f2.write(f'{flds[0]}\\tQ0\\t{flds[2]}\\t0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60d96d74-be2a-4eb2-b35a-4fe7b7f8f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel_graded_tsv(NTCIR2 + '/rels/rel2_ntc2-je2_0101-0149.nc.utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e74520e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rel1_ntc2-e2_0101-0149',\n",
       " 'rel1_ntc2-e2_0101-0149.nc',\n",
       " 'rel1_ntc2-j2_0101-0149',\n",
       " 'rel1_ntc2-j2_0101-0149.nc',\n",
       " 'rel1_ntc2-je2_0101-0149',\n",
       " 'rel1_ntc2-je2_0101-0149.nc',\n",
       " 'rel2_ntc2-e2_0101-0149',\n",
       " 'rel2_ntc2-e2_0101-0149.nc',\n",
       " 'rel2_ntc2-j2_0101-0149',\n",
       " 'rel2_ntc2-j2_0101-0149.nc',\n",
       " 'rel2_ntc2-je2_0101-0149',\n",
       " 'rel2_ntc2-je2_0101-0149.nc',\n",
       " 'rel2_ntc2-je2_0101-0149.nc.utf8',\n",
       " 'rel2_ntc2-je2_0101-0149.nc.utf8.tsv']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(NTCIR2 + '/rels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb04a7-afaa-4e51-893a-e3fe333d4d9f",
   "metadata": {},
   "source": [
    "### Register to ir_datasets module locally\n",
    "\n",
    "- Dataset name: `ntcir-transfer`\n",
    "- subset: `2/valid`\n",
    "\n",
    "#### Location of dataset files\n",
    "\n",
    "- `../datasets/ntcir-transfer.yaml`\n",
    "- `../datasets/ntcir_transfer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "072cd480-a664-4642-8530-8312a94f13b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -q ir_datasets pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2370217-439a-4f5f-817f-aa49d6eefdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.dirname(os.path.abspath('__file__')), '../datasets'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e89f647-9cb3-49df-952d-38fe76e920a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_datasets\n",
    "import ntcir_transfer\n",
    "dataset = ir_datasets.load('ntcir-transfer/2/valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58ad4f01-76d9-45e9-bf04-e12a4ede4977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': str, 'text': str}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.docs_cls().__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7e2ffc-9278-4db3-a76e-261a06dbbd9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docstore = dataset.docs_store()\n",
    "docstore.get('kaken-e-2469487463').text # the one in the overview paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0298cd7f-8b7c-4dff-be55-298af89c756f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_id': str, 'text': str}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.queries_cls().__annotations__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f768e-ef23-4913-b38f-4d48be553249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(dataset.queries_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c080c32-8868-4cb3-946e-d910bc2ed349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 'relevant', 1: 'partially relevant', 0: 'not relevant'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.qrels_defs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89949e0-8a73-4e12-bd63-16ab0e95e54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(dataset.qrels_iter())"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m102",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m102"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
